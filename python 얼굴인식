import os
import cv2
import keyboard
import numpy as np
from os import listdir
from os.path import isfile, join
import warnings
warnings.filterwarnings("ignore", category=np.VisibleDeprecationWarning)

isTrue = False

#1.얼굴 사진 찍기
face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

#전체 사진에서 얼굴 부위만 잘라 리턴
def face_extractor(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  #흑백처리
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)  #얼굴 찾기
    if faces == ():  #찾은 얼굴이 없으면 None으로 리턴
        return None

    for(x,y,w,h) in faces:  #얼굴들이 있으면
        cropped_face = img[y: y + h, x: x + w]  #해당 얼굴 크기만큼 cropped_face에 잘라 넣기

    return cropped_face

print("")
print("Colleting..")
print("")

cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  #카메라 실행

count = 0  #저장할 이미지 카운트 변수
countIs = 0

while True:
    ret, frame = cap.read()  #카메라로 부터 사진 1장 얻기
    frame = cv2.flip(frame, +1)  #이미지 좌우반전

    if face_extractor(frame) is not None:  #얼굴 감지 하여 얼굴만 가져오기
        count += 1
        countIs = 0
        face = cv2.resize(face_extractor(frame), (450, 450))  #얼굴 이미지 크기를 500x500으로 조정
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)  #조정된 이미지를 흑백으로 변환
        file_name_path = 'faces/user' + str(count) + '.jpg'  #faces폴더에 jpg파일로 저장  #ex > faces/user0.jpg   faces/user1.jpg ....
        cv2.imwrite(file_name_path, face)

        cv2.putText(face, str(count), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)  #화면에 얼굴과 현재 저장 개수 표시
        cv2.imshow('Face Cropper', face)
    else:
        countIs += 1
        if countIs == 1:
            print("[INFO] Face not Found")
        else:
            countIs = 2
        pass

    if cv2.waitKey(1) == 13 or count == 1000:
        break

    if keyboard.is_pressed('e'):
        break

cap.release()
cv2.destroyAllWindows()

print("")
print("Colleting Samples Complete!!!")
print("")

#2.얼굴 학습
data_path = 'faces/'
onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]  #faces폴더에 있는 파일 리스트 얻기
Training_Data, Labels = [], []  #데이터와 매칭될 라벨 변수

print("")
print("Training..")
print("")

for i, files in enumerate(onlyfiles):  #파일 개수 만큼 루프
    image_path = data_path + onlyfiles[i]
    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  #이미지 불러오기

    if images is None:  #이미지 파일이 아니거나 못 읽어 왔다면 무시
        continue

    Training_Data.append(np.asarray(images, dtype=np.uint8))  #Training_Data 리스트에 이미지를 바이트 배열로 추가
    Labels.append(i)  #Labels 리스트엔 카운트 번호 추가
    print("[Traning] user" + str(i + 1) + ".jpg")

if len(Labels) == 0:  #훈련할 데이터가 없다면 종료.
    print("There is no data to train.")
    exit()

Labels = np.asarray(Labels, dtype = np.int32)  #Labels를 32비트 정수로 변환

model = cv2.face.LBPHFaceRecognizer_create()  #모델 생성
model.train(np.asarray(Training_Data), np.asarray(Labels))  #학습 시작

print("")
print("Model Training Complete!!!!!")
print("")

#3.얼굴 인식
def face_detector(img, size = 0.5):
    global isTrue
    global frame_cp

    alpha = 0.8
    offset = 25
    offset2 = 7
    thickness = 2

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)

    if faces == ():
        return img, []

    for (x, y, w, h) in faces:

        #얼굴 부위 표시하기
        cv2.rectangle(img, (x + offset2, y + offset2), (x + w - offset2, y + h - offset2),(255, 255, 255), 1)

        cv2.line(img, (x, y), (x + offset, y), (255, 255, 255), thickness)
        cv2.line(img, (x, y), (x, y + offset), (255, 255, 255), thickness)
        cv2.line(img, (x + w, y), (x + w - offset, y), (255, 255, 255), thickness)
        cv2.line(img, (x + w, y), (x + w, y + offset), (255, 255, 255), thickness)
        cv2.line(img, (x, y + h), (x + offset, y + h), (255, 255, 255), thickness)
        cv2.line(img, (x, y + h), (x, y + h - offset), (255, 255, 255), thickness)
        cv2.line(img, (x + w, y + h), (x + w - offset, y + h), (255, 255, 255), thickness)
        cv2.line(img, (x + w, y + h), (x + w, y + h - offset), (255, 255, 255), thickness)

        roi = img[y: y + h, x: x + w]
        roi = cv2.resize(roi, (200, 200))

        img = cv2.addWeighted(img, alpha, frame_cp, 1 - alpha, 0)

        if isTrue:
            cv2.putText(img, display_string, (x, y - 13), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

    return img, roi   #검출된 좌표에 사각 박스 그리고(img), 검출된 부위를 잘라(roi) 전달

print("")
print("Turn on the camera!")

cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  #카메라 열기

while True:
    ret, frame = cap.read()  #카메라로 부터 사진 한장 읽기
    frame = cv2.flip(frame, +1)  #이미지 좌우반전
    ret, frame_cp = cap.read()  #카메라로 부터 사진 한장 읽기
    frame_cp = cv2.flip(frame_cp, +1)  #이미지 좌우반전

    image, face = face_detector(frame)  # 얼굴 검출 시도
    try:
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)  #검출된 사진을 흑백으로 변환
        result = model.predict(face)  #학습한 모델로 예측시도

        if result[1] < 500:  #result[1]은 신뢰도이고 0에 가까울수록 자신과 같다는 뜻이다.
            confidence = int(100 * (1 - (result[1]) / 300))  #유사도 계산
            display_string = str(confidence) + '%'  # 유사도 화면에 표시
            isTrue = True

        if confidence > 85:  #85% 보다 크면 동일 인물로 간주해 UnLocked!
            cv2.putText(image, "Unlocked", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.imshow('Face Cropper', image)
        else:  #85% 이하면 타인.. Locked!!!
            cv2.putText(image, "Locked", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            cv2.imshow('Face Cropper', image)
    except:  #얼굴 검출 안됨
        cv2.putText(image, "Face Not Found", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.imshow('Face Cropper', image)
        pass

    if cv2.waitKey(1) == 13:
        break

    if keyboard.is_pressed('e'):
        print("")
        print("Turn off the camera!")
        break

def removeAllFile(file_path):  #faces 폴더 내의 모든 파일 삭제
    if os.path.exists(file_path):
        for file in os.scandir(file_path):
            os.remove(file.path)
        return "Remove All File"
    else:
        return "Diretory Not Found"

file_path = 'faces/'
removeAllFile(file_path)

cap.release()
cv2.destroyAllWindows()
